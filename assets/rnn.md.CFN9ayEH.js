import{_ as i,c as t,o as s,M as e}from"./chunks/framework.Dt16nE2a.js";const y=JSON.parse('{"title":"Vanilla RNN 🍦 to Structured SSM","description":"","frontmatter":{},"headers":[],"relativePath":"rnn.md","filePath":"rnn.md"}'),a={name:"rnn.md"},n=e(`<h1 id="vanilla-rnn-🍦-to-structured-ssm" tabindex="-1">Vanilla RNN 🍦 to Structured SSM <a class="header-anchor" href="#vanilla-rnn-🍦-to-structured-ssm" aria-label="Permalink to &quot;Vanilla RNN 🍦 to Structured SSM&quot;">​</a></h1><p>Date: February 1, 2024</p><div class="tip custom-block"><p class="custom-block-title">This article is a work in progress</p></div><p>Understanding state space models (SSM’s) felt daunting to me.</p><p>But once I understood the origin of SSM’s and how they were built upon the principles of Recurrent Neural Networks (RNN’s), they became more intuitive.</p><p>Here, we will implement an RNN, convert it into a vanilla SSM and then implement modern techniques in deep sequence modeling to build a <em>structured</em> SSM.</p><hr><p>Let’s first take a look at the basic function signature of an RNN block:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes catppuccin-macchiato night-owl vp-code"><code><span class="line"><span style="--shiki-light:#C6A0F6;--shiki-dark:#C792EA;">def</span><span style="--shiki-light:#8AADF4;--shiki-dark:#82AAFF;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"> RNN_block</span><span style="--shiki-light:#939AB7;--shiki-dark:#D9F5DD;">(</span><span style="--shiki-light:#EE99A0;--shiki-dark:#7FDBCA;--shiki-light-font-style:italic;--shiki-dark-font-style:inherit;">x</span><span style="--shiki-light:#939AB7;--shiki-dark:#D6DEEB;">,</span><span style="--shiki-light:#EE99A0;--shiki-dark:#7FDBCA;--shiki-light-font-style:italic;--shiki-dark-font-style:inherit;"> prev_hidden_state</span><span style="--shiki-light:#939AB7;--shiki-dark:#D9F5DD;">)</span><span style="--shiki-light:#939AB7;--shiki-dark:#D6DEEB;"> -&gt;</span><span style="--shiki-light:#F5A97F;--shiki-dark:#C5E478;--shiki-light-font-style:italic;--shiki-dark-font-style:inherit;"> tuple</span><span style="--shiki-light:#939AB7;--shiki-dark:#D6DEEB;">:</span></span>
<span class="line"><span style="--shiki-light:#6E738D;--shiki-dark:#637777;--shiki-light-font-style:italic;--shiki-dark-font-style:inherit;">		#</span><span style="--shiki-light:#6E738D;--shiki-dark:#637777;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"> perform linear operations and activation</span></span>
<span class="line"><span style="--shiki-light:#C6A0F6;--shiki-dark:#C792EA;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">    return</span><span style="--shiki-light:#CAD3F5;--shiki-dark:#D6DEEB;"> y</span><span style="--shiki-light:#939AB7;--shiki-dark:#D6DEEB;">,</span><span style="--shiki-light:#CAD3F5;--shiki-dark:#D6DEEB;"> new_hidden_state</span></span></code></pre></div><p>The block takes in an input <code>x</code> and the previous hidden state <code>prev_hidden_state</code></p><p>The block returns a tuple, containing the output <code>y</code> and the updated hidden state <code>new_hidden_state</code></p>`,11),l=[n];function h(r,o,p,d,k,c){return s(),t("div",null,l)}const g=i(a,[["render",h]]);export{y as __pageData,g as default};
